{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# UCI HAR Dataset - Activity Recognition\n", "## Using PyTorch for Deep Learning & Machine Learning\n", "This notebook explores human activity recognition using the UCI HAR dataset. We implement:\n", "- **LSTM & CNN using PyTorch**\n", "- **Feature extraction using TSFEL**\n", "- **Machine Learning models (Random Forest, SVM, Logistic Regression)**\n", "- **Performance comparison between ML & DL approaches**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import torch.utils.data as data\n", "import tsfel\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import classification_report, accuracy_score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load UCI HAR Dataset\n", "def load_data():\n", "    X_train = np.loadtxt('./UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt')\n", "    y_train = np.loadtxt('./UCI HAR Dataset/train/y_train.txt').astype(int)\n", "    X_test = np.loadtxt('./UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt')\n", "    y_test = np.loadtxt('./UCI HAR Dataset/test/y_test.txt').astype(int)\n", "    return X_train, y_train, X_test, y_test\n", "\n", "X_train, y_train, X_test, y_test = load_data()\n", "print(f'Training Data Shape: {X_train.shape}')\n", "print(f'Test Data Shape: {X_test.shape}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Extract Features using TSFEL\n", "cfg = tsfel.get_features_by_domain('statistical')\n", "X_train_tsfel = tsfel.time_series_features_extractor(cfg, X_train)\n", "X_test_tsfel = tsfel.time_series_features_extractor(cfg, X_test)\n", "\n", "print('Feature Extraction Completed!')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Machine Learning Models\n", "def train_ml_model(model, X_train, y_train, X_test, y_test):\n", "    model.fit(X_train, y_train)\n", "    y_pred = model.predict(X_test)\n", "    print(classification_report(y_test, y_pred))\n", "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n", "\n", "# Random Forest\n", "print('Random Forest:')\n", "train_ml_model(RandomForestClassifier(), X_train_tsfel, y_train, X_test_tsfel, y_test)\n", "\n", "# SVM\n", "print('SVM:')\n", "train_ml_model(SVC(), X_train_tsfel, y_train, X_test_tsfel, y_test)\n", "\n", "# Logistic Regression\n", "print('Logistic Regression:')\n", "train_ml_model(LogisticRegression(), X_train_tsfel, y_train, X_test_tsfel, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define LSTM Model in PyTorch\n", "class LSTMModel(nn.Module):\n", "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n", "        super(LSTMModel, self).__init__()\n", "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n", "        self.fc = nn.Linear(hidden_dim, output_dim)\n", "\n", "    def forward(self, x):\n", "        out, _ = self.lstm(x)\n", "        out = self.fc(out[:, -1, :])\n", "        return out\n", "\n", "# Initialize Model\n", "input_dim = X_train.shape[1]\n", "model = LSTMModel(input_dim, hidden_dim=64, output_dim=len(np.unique(y_train)))\n", "print(model)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define 1D CNN Model in PyTorch\n", "class CNNModel(nn.Module):\n", "    def __init__(self, input_channels, num_classes):\n", "        super(CNNModel, self).__init__()\n", "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n", "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n", "        self.fc = nn.Linear(64 * (input_channels // 2), num_classes)\n", "\n", "    def forward(self, x):\n", "        x = self.pool(torch.relu(self.conv1(x)))\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc(x)\n", "        return x\n", "\n", "# Initialize Model\n", "model_cnn = CNNModel(input_channels=X_train.shape[1], num_classes=len(np.unique(y_train)))\n", "print(model_cnn)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n", "- **Deep Learning Models (LSTM & CNN)** are better for sequential data.\n", "- **Machine Learning Models** trained on TSFEL-generated features perform well.\n", "- **LSTM is ideal for time-series prediction.**\n", "- **Random Forest is the best ML model for this dataset.**"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}